{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9887af2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T00:56:53.741481900Z",
     "start_time": "2024-03-10T00:56:46.701347300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ta \n",
    "import optuna \n",
    "import time\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations, chain \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93900597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d_train = pd.read_csv(\"../data/aapl_1d_train.csv\")\n",
    "data_1d_train = data_1d_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1m_train = pd.read_csv(\"../data/aapl_1m_train.csv\")\n",
    "data_1m_train = data_1m_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1h_train = pd.read_csv(\"../data/aapl_1h_train.csv\")\n",
    "data_1h_train = data_1h_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f536b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5m_train = pd.read_csv(\"../data/aapl_5m_train.csv\")\n",
    "data_5m_train = data_5m_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5487a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    return chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487923c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_features(data, ds_type: str):\n",
    "    data1=pd.DataFrame()\n",
    "    #Calcular indicadores tecnicos\n",
    "    cmf_data = ta.volume.ChaikinMoneyFlowIndicator(data.High, data.Low, data.Close, data.Volume, window = 14)\n",
    "    rsi_data = ta.momentum.RSIIndicator(data.Close, window=14)\n",
    "    \n",
    "    data1[\"CMF\"] = cmf_data.chaikin_money_flow()\n",
    "    data1[\"RSI\"] = rsi_data.rsi()\n",
    "    # Calcular la volatilidad\n",
    "    data1['Volatility'] = data['High'] - data['Low']\n",
    "    data1['Close_Lag0'] = data['Close']\n",
    "    # Calcular las tendencias\n",
    "    for i in range(1, 5 + 1):\n",
    "        data1[f'Close_Lag{i}'] = data['Close'].shift(i)\n",
    "    #Variable ded respuesta\n",
    "    if ds_type == \"buy\":\n",
    "        data1['Response'] = (data['Close'] < data['Close'].shift(-10))\n",
    "    else:\n",
    "        data1['Response'] = (data['Close'] > data['Close'].shift(-10))\n",
    "    \n",
    "    data1 = data1.drop(data1.index[:30])\n",
    "    data1 = data1.drop(data1.index[-30:])\n",
    "    data1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataresult_long_1d_train = file_features(data_1d_train, ds_type=\"buy\")\n",
    "dataresult_short_1d_train = file_features(data_1d_train, ds_type=\"sell\")\n",
    "dataresult_long_1m_train = file_features(data_1m_train, ds_type=\"buy\")\n",
    "dataresult_short_1m_train = file_features(data_1m_train, ds_type=\"sell\")\n",
    "dataresult_long_1h_train = file_features(data_1h_train, ds_type=\"buy\")\n",
    "dataresult_short_1h_train = file_features(data_1h_train, ds_type=\"sell\")\n",
    "dataresult_long_5m_train = file_features(data_5m_train, ds_type=\"buy\")\n",
    "dataresult_short_5m_train = file_features(data_5m_train, ds_type=\"sell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5da633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_log_regresor(trial, data):\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Definir los parámetros a optimizar\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    C = trial.suggest_loguniform('C', 0.001, 1000)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "\n",
    "    # Crear el modelo de regresión logística con los parámetros sugeridos\n",
    "    model = LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=10_000, random_state=123)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "##%%\n",
    "def objective_svm(trial, data):\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Definir los parámetros a optimizar\n",
    "    C = trial.suggest_loguniform('C', 0.001, 1000)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 5)\n",
    "    else:\n",
    "        degree = 3  # Valor predeterminado si el kernel no es 'poly'\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    # Crear el modelo SVM con los parámetros sugeridos\n",
    "    model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, max_iter=100_000, random_state=123)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "##%%\n",
    "def objective_xgboost(trial, data):\n",
    "    data = data.copy()\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    # Definir los parámetros a optimizar\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1.0, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, 0.1)\n",
    "    # Crear el modelo XGBoost con los parámetros sugeridos\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=123\n",
    "    )\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "##%%\n",
    "def optimize_params_log_regresor(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_log_regresor(trial, data)\n",
    "    \n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=2)\n",
    "\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "##%%\n",
    "def optimize_params_svm(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_svm(trial, data)\n",
    "    \n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=2)\n",
    "\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "##%%\n",
    "def optimize_params_xgboost(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_xgboost(trial, data)\n",
    "    \n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=2)\n",
    "\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "##%%\n",
    "def optimize_params(data):\n",
    "    # Optimización de regresión logística\n",
    "    best_params_lr, best_accuracy_lr = optimize_params_log_regresor(data)\n",
    "    print(\"Mejores parámetros de regresión logística:\", best_params_lr)\n",
    "    print(\"Precisión del modelo de regresión logística:\", best_accuracy_lr)\n",
    "    # Optimización de SVM\n",
    "    best_params_svm, best_accuracy_svm = optimize_params_svm(data)\n",
    "    print(\"Mejores parámetros de SVM:\", best_params_svm)\n",
    "    print(\"Precisión del modelo de SVM:\", best_accuracy_svm)\n",
    "    # Optimización de XGBoost\n",
    "    best_params_xgb, best_accuracy_xgb = optimize_params_xgboost(data)\n",
    "    print(\"Mejores parámetros de XGBoost:\", best_params_xgb)\n",
    "    print(\"Precisión del modelo de XGBoost:\", best_accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab1196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:14,709] A new study created in memory with name: no-name-a0ef3fc5-4553-4b49-9fdf-d2cd01c84eaf\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
      "[I 2024-03-09 15:13:14,729] Trial 0 finished with value: 0.6555023923444976 and parameters: {'penalty': 'l2', 'C': 0.02054362589578733, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6555023923444976.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
      "[I 2024-03-09 15:13:15,194] Trial 1 finished with value: 0.6631578947368421 and parameters: {'penalty': 'l1', 'C': 0.008798139830459064, 'solver': 'saga'}. Best is trial 1 with value: 0.6631578947368421.\n",
      "[I 2024-03-09 15:13:15,194] A new study created in memory with name: no-name-ca166ff5-a6c9-45ab-8658-b2344d48553b\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de regresión logística: {'penalty': 'l1', 'C': 0.008798139830459064, 'solver': 'saga'}\n",
      "Precisión del modelo de regresión logística: 0.6631578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:15,806] Trial 0 finished with value: 0.6593301435406699 and parameters: {'C': 37.29423057590281, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.6593301435406699.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
      "C:\\Users\\elias\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-03-09 15:13:17,077] Trial 1 finished with value: 0.6593301435406699 and parameters: {'C': 0.0019177197723385766, 'kernel': 'linear'}. Best is trial 0 with value: 0.6593301435406699.\n",
      "[I 2024-03-09 15:13:17,077] A new study created in memory with name: no-name-4216f604-c1d5-4c41-b0c4-81d62ff2df36\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:57: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1.0, 0.1)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:58: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de SVM: {'C': 37.29423057590281, 'kernel': 'sigmoid', 'gamma': 'auto'}\n",
      "Precisión del modelo de SVM: 0.6593301435406699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:18,035] Trial 0 finished with value: 0.5291866028708134 and parameters: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.4621973561135585, 'subsample': 1.0, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.5291866028708134.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:57: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1.0, 0.1)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:58: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, 0.1)\n",
      "[I 2024-03-09 15:13:18,193] Trial 1 finished with value: 0.6181818181818182 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.02353186669766063, 'subsample': 0.8, 'colsample_bytree': 1.0}. Best is trial 1 with value: 0.6181818181818182.\n",
      "[I 2024-03-09 15:13:18,193] A new study created in memory with name: no-name-68759755-0447-425c-a824-88a93d66dca2\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de XGBoost: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.02353186669766063, 'subsample': 0.8, 'colsample_bytree': 1.0}\n",
      "Precisión del modelo de XGBoost: 0.6181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:19,380] Trial 0 finished with value: 0.6602870813397129 and parameters: {'penalty': 'l1', 'C': 391.6055943510264, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6602870813397129.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
      "[I 2024-03-09 15:13:25,034] Trial 1 finished with value: 0.6593301435406699 and parameters: {'penalty': 'l1', 'C': 40.27133752652738, 'solver': 'saga'}. Best is trial 0 with value: 0.6602870813397129.\n",
      "[I 2024-03-09 15:13:25,034] A new study created in memory with name: no-name-55f014a6-2fa6-4e9a-b577-d86423366854\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de regresión logística: {'penalty': 'l1', 'C': 391.6055943510264, 'solver': 'liblinear'}\n",
      "Precisión del modelo de regresión logística: 0.6602870813397129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:26,391] Trial 0 finished with value: 0.661244019138756 and parameters: {'C': 34.154290341054214, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.661244019138756.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n",
      "C:\\Users\\elias\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-03-09 15:13:28,003] Trial 1 finished with value: 0.5550239234449761 and parameters: {'C': 0.13634823458733597, 'kernel': 'linear'}. Best is trial 0 with value: 0.661244019138756.\n",
      "[I 2024-03-09 15:13:28,003] A new study created in memory with name: no-name-2ccf73b5-62c2-4ebc-909b-d1b3e04fe30d\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:57: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1.0, 0.1)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:58: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de SVM: {'C': 34.154290341054214, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "Precisión del modelo de SVM: 0.661244019138756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 15:13:28,346] Trial 0 finished with value: 0.5732057416267943 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.01845611375279615, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 0 with value: 0.5732057416267943.\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:57: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1.0, 0.1)\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:58: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, 0.1)\n",
      "[I 2024-03-09 15:13:29,306] Trial 1 finished with value: 0.5607655502392345 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.06786781783358023, 'subsample': 0.6, 'colsample_bytree': 1.0}. Best is trial 0 with value: 0.5732057416267943.\n",
      "[I 2024-03-09 15:13:29,307] A new study created in memory with name: no-name-4aa093f2-eb91-4323-a32a-c31c05b28131\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_21392\\2072222332.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.001, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de XGBoost: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.01845611375279615, 'subsample': 0.7, 'colsample_bytree': 0.9}\n",
      "Precisión del modelo de XGBoost: 0.5732057416267943\n"
     ]
    }
   ],
   "source": [
    "params_1d_long = optimize_params(dataresult_long_1d_train)\n",
    "params_1d_short = optimize_params(dataresult_short_1d_train)\n",
    "params_1m_long = optimize_params(dataresult_long_1m_train)\n",
    "params_1m_short = optimize_params(dataresult_short_1m_train)\n",
    "params_1h_long = optimize_params(dataresult_long_1h_train)\n",
    "params_1h_short = optimize_params(dataresult_short_1h_train)\n",
    "params_5m_long = optimize_params(dataresult_long_5m_train)\n",
    "params_5m_short = optimize_params(dataresult_short_5m_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f9b40",
   "metadata": {},
   "source": [
    "Escogemos los mejores parametros, en este caso el porcentaje de accuracy no representa gran diferencia entre todos los data sets, por lo que escogemos el dataset de 1d, para trabajar de manera mas eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26844608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_signals(data):\n",
    "    buy_signals = pd.DataFrame()\n",
    "    # Selecciona las características\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "    # Crear modelos con los mejores parámetros encontrados para cada algoritmo\n",
    "    best_logistic_model = LogisticRegression(penalty= 'l1', C= 0.008798139830459064, solver= 'saga')\n",
    "    best_svm_model = SVC(C= 37.29423057590281, kernel= 'sigmoid', gamma= 'auto')\n",
    "    best_xgboost_model = XGBClassifier(n_estimators= 100, max_depth= 8, learning_rate= 0.02353186669766063, subsample= 0.8, colsample_bytree= 1.0)\n",
    "\n",
    "    # Entrenar los modelos con todo el conjunto de datos original\n",
    "    best_logistic_model.fit(X, y)\n",
    "    best_svm_model.fit(X, y)\n",
    "    best_xgboost_model.fit(X, y)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de datos original\n",
    "    predictions_lr = best_logistic_model.predict(X)\n",
    "    predictions_svm = best_svm_model.predict(X)\n",
    "    predictions_xgboost = best_xgboost_model.predict(X)\n",
    "    predictions_xgboost_bool = predictions_xgboost.astype(bool)\n",
    "\n",
    "\n",
    "    # Agregar las predicciones como nuevas columnas al conjunto de datos original\n",
    "    buy_signals['predicciones_lr'] = predictions_lr\n",
    "    buy_signals['predicciones_svm'] = predictions_svm\n",
    "    buy_signals['predicciones_xgboost'] = predictions_xgboost_bool\n",
    "\n",
    "    return buy_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sell_signals(data):\n",
    "    sell_signals = pd.DataFrame()\n",
    "    # Selecciona las características\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "    # Crear modelos con los mejores parámetros encontrados para cada algoritmo\n",
    "    best_logistic_model = LogisticRegression(penalty='l1', C=391.6055943510264, solver='liblinear')\n",
    "    best_svm_model = SVC(C=34.154290341054214, kernel='rbf', gamma='scale')\n",
    "    best_xgboost_model = XGBClassifier(n_estimators=300, max_depth=7, learning_rate=0.01845611375279615, subsample=0.7,\n",
    "                                       colsample_bytree=0.9)\n",
    "\n",
    "    # Entrenar los modelos con todo el conjunto de datos original\n",
    "    best_logistic_model.fit(X, y)\n",
    "    best_svm_model.fit(X, y)\n",
    "    best_xgboost_model.fit(X, y)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de datos original\n",
    "    predictions_lr = best_logistic_model.predict(X)\n",
    "    predictions_svm = best_svm_model.predict(X)\n",
    "    predictions_xgboost = best_xgboost_model.predict(X)\n",
    "    predictions_xgboost_bool = predictions_xgboost.astype(bool)\n",
    "\n",
    "    # Agregar las predicciones como nuevas columnas al conjunto de datos original\n",
    "    sell_signals['predicciones_lr'] = predictions_lr\n",
    "    sell_signals['predicciones_svm'] = predictions_svm\n",
    "    sell_signals['predicciones_xgboost'] = predictions_xgboost_bool\n",
    "\n",
    "    return sell_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_buy_signals = buy_signals(dataresult_long_1d_train)\n",
    "global_sell_signals = sell_signals(dataresult_short_1d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, buy_signals, sell_signals, stop_loss, take_profit, n_shares):\n",
    "            history = []\n",
    "            active_operations = []\n",
    "            cash = 1_000_000\n",
    "            com = 1.25 / 100\n",
    "\n",
    "            for i, row in data.iterrows():\n",
    "                # close active operation\n",
    "                active_op_temp = []\n",
    "                for operation in active_operations:\n",
    "                    if operation[\"stop_loss\"] > row.Close:\n",
    "                        cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                    elif operation[\"take_profit\"] < row.Close:\n",
    "                        cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                    else:\n",
    "                        active_op_temp.append(operation)\n",
    "                active_operations = active_op_temp\n",
    "\n",
    "                # check if we have enough cash\n",
    "                if cash < (row.Close * (1 + com)):\n",
    "                    asset_vals = sum([operation[\"n_shares\"] * row.Close for operation in active_operations])\n",
    "                    portfolio_value = cash + asset_vals\n",
    "                    continue\n",
    "\n",
    "                # Apply buy signals\n",
    "                if buy_signals.loc[i].any():\n",
    "                    active_operations.append({\n",
    "                        \"bought\": row.Close,\n",
    "                        \"n_shares\": n_shares,\n",
    "                        \"stop_loss\": row.Close * stop_loss,\n",
    "                        \"take_profit\": row.Close * take_profit\n",
    "                    })\n",
    "\n",
    "                    cash -= row.Close * (1 + com) * n_shares\n",
    "\n",
    "                # Apply sell signals\n",
    "                if sell_signals.loc[i].any():\n",
    "                    active_op_temp = []\n",
    "                    for operation in active_operations:\n",
    "                        if operation[\"take_profit\"] < row.Close or operation[\"stop_loss\"] > row.Close:\n",
    "                            cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                        else:\n",
    "                            active_op_temp.append(operation)\n",
    "                    active_operations = active_op_temp\n",
    "\n",
    "                asset_vals = sum([operation[\"n_shares\"] * row.Close for operation in active_operations])\n",
    "                portfolio_value = cash + asset_vals\n",
    "\n",
    "            return portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial, strategy, data):\n",
    "    portfolio_value = 0\n",
    "\n",
    "    stop_loss = trial.suggest_float(\"stop_loss\", 0.80, 0.90)\n",
    "    take_profit = trial.suggest_float(\"take_profit\", 1.01, 1.10)\n",
    "    n_shares = trial.suggest_int(\"n_shares\", 20, 50)\n",
    "\n",
    "    strat_params = {}\n",
    "\n",
    "    buy_signals = pd.DataFrame()\n",
    "    sell_signals = pd.DataFrame()\n",
    "\n",
    "    if \"logistic\" in strategy:\n",
    "        buy_signals[\"logistic\"] = global_buy_signals[\"predicciones_lr\"]\n",
    "        sell_signals[\"logistic\"] = global_sell_signals[\"predicciones_lr\"]\n",
    "        \n",
    "    if \"svm\" in strategy:\n",
    "        buy_signals[\"svm\"] = global_buy_signals[\"predicciones_svm\"]\n",
    "        sell_signals[\"svm\"] = global_sell_signals[\"predicciones_svm\"]\n",
    "        \n",
    "    if \"xg\" in strategy:\n",
    "        buy_signals[\"xg\"] = global_buy_signals[\"predicciones_xgboost\"]\n",
    "        sell_signals[\"xg\"] = global_sell_signals[\"predicciones_xgboost\"]\n",
    "    \n",
    "    return backtest(data, buy_signals, sell_signals, stop_loss, take_profit, n_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_file(data):\n",
    "    data = data.drop(data.index[:30])\n",
    "    data = data.drop(data.index[-30:])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    strategies = list(powerset([\"logistic\", \"svm\", \"xg\"]))\n",
    "    best_strat = None\n",
    "    best_val = -1\n",
    "    best_params = None\n",
    "\n",
    "    for strat in strategies:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda x: optimize(x, strat, data), n_trials=15)\n",
    "        value = study.best_value\n",
    "        if value > best_val:\n",
    "            best_val = value\n",
    "            best_strat = strat\n",
    "            best_params = study.best_params\n",
    "    print(study.best_value)\n",
    "    print(best_strat)\n",
    "    print(best_params)\n",
    "\n",
    "    return {\"file\": data,\n",
    "            \"strat\": best_strat,\n",
    "            \"value\": best_val,\n",
    "            \"params\": best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1d_test = optimize_file(data_1d_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
