{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9887af2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T00:56:53.741481900Z",
     "start_time": "2024-03-10T00:56:46.701347300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ta \n",
    "import optuna \n",
    "import time\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations, chain \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5487a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    return chain.from_iterable(combinations(s,r) for r in range(1,len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487923c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_features(data, ds_type: str):\n",
    "    data1=pd.DataFrame()\n",
    "    #Calcular indicadores tecnicos\n",
    "    cmf_data = ta.volume.ChaikinMoneyFlowIndicator(data.High, data.Low, data.Close, data.Volume, window = 14)\n",
    "    rsi_data = ta.momentum.RSIIndicator(data.Close, window=14)\n",
    "    \n",
    "    data1[\"CMF\"] = cmf_data.chaikin_money_flow()\n",
    "    data1[\"RSI\"] = rsi_data.rsi()\n",
    "    # Calcular la volatilidad\n",
    "    data1['Volatility'] = data['High'] - data['Low']\n",
    "    data1['Close_Lag0'] = data['Close']\n",
    "    # Calcular las tendencias\n",
    "    for i in range(1, 5 + 1):\n",
    "        data1[f'Close_Lag{i}'] = data['Close'].shift(i)\n",
    "    #Variable ded respuesta\n",
    "    if ds_type == \"buy\":\n",
    "        data1['Response'] = (data['Close'] < data['Close'].shift(-10))\n",
    "    else:\n",
    "        data1['Response'] = (data['Close'] > data['Close'].shift(-10))\n",
    "    \n",
    "    data1 = data1.drop(data1.index[:30])\n",
    "    data1 = data1.drop(data1.index[-30:])\n",
    "    data1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f25ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dnn_1(trial, data, threshold=0.5):\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    # Definir los parámetros a optimizar\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    num_units = [trial.suggest_int(f'num_units_layer_{i}', 32, 256) for i in range(num_layers)]\n",
    "    activations = [trial.suggest_categorical(f'activation_layer_{i}', ['relu', 'sigmoid', 'tanh']) for i in range(num_layers)]\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "    for i in range(num_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_units[i], activation=activations[i]))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # Definir Early Stopping para evitar overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    # Calcular las predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Redondear las predicciones si superan el umbral\n",
    "    y_pred_rounded = (y_pred > threshold).astype('int32')\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    accuracy = accuracy_score(y_test, y_pred_rounded)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d700245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dnn_2(trial, data, threshold=0.5):\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    # Definir los parámetros a optimizar\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 6)\n",
    "    num_units = [trial.suggest_int(f'num_units_layer_{i}', 64, 256) for i in range(num_layers)]\n",
    "    activations = [trial.suggest_categorical(f'activation_layer_{i}', ['relu', 'sigmoid', 'selu']) for i in range(num_layers)]\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "    for i in range(num_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_units[i], activation=activations[i]))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # Definir Early Stopping para evitar overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    # Calcular las predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Redondear las predicciones si superan el umbral\n",
    "    y_pred_rounded = (y_pred > threshold).astype('int32')\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    accuracy = accuracy_score(y_test, y_pred_rounded)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca54ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dnn_3(trial, data, threshold=0.5):\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X = data.iloc[:, :-1]\n",
    "    # Selecciona la variable objetivo\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    # Definir los parámetros a optimizar\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 6)\n",
    "    num_units = [trial.suggest_int(f'num_units_layer_{i}', 64, 512) for i in range(num_layers)]\n",
    "    activations = [trial.suggest_categorical(f'activation_layer_{i}', ['relu', 'elu', 'selu']) for i in range(num_layers)]\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "    for i in range(num_layers):\n",
    "        model.add(tf.keras.layers.Dense(units=num_units[i], activation=activations[i]))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # Definir Early Stopping para evitar overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "    # Calcular las predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Redondear las predicciones si superan el umbral\n",
    "    y_pred_rounded = (y_pred > threshold).astype('int32')\n",
    "    # Calcular la precisión en el conjunto de prueba\n",
    "    accuracy = accuracy_score(y_test, y_pred_rounded)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac61309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params_dnn_1(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_dnn_1(trial, data)\n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=20)\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "    return best_params, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3de2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params_dnn_2(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_dnn_2(trial, data)\n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=20)\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "    return best_params, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e604b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params_dnn_3(data):\n",
    "    # Crear un estudio Optuna para la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    # Función objetivo con el dataset como parámetro fijo\n",
    "    objective_fn = lambda trial: objective_dnn_3(trial, data)\n",
    "    # Ejecutar la optimización\n",
    "    study.optimize(objective_fn, n_trials=20)\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "    return best_params, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5da633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_params(data):\n",
    "    # Optimización de DNN 1\n",
    "    best_params_dnn_1, best_accuracy_dnn_1 = optimize_params_dnn_1(data)\n",
    "    print(\"Mejores parámetros de DNN 1:\", best_params_dnn_1)    \n",
    "    # Optimización de DNN 2\n",
    "    best_params_dnn_2, best_accuracy_dnn_2 = optimize_params_dnn_2(data)\n",
    "    print(\"Mejores parámetros de DNN 2:\", best_params_dnn_2)    \n",
    "    # Optimización de DNN 3\n",
    "    best_params_dnn_3, best_accuracy_dnn_3 = optimize_params_dnn_3(data)\n",
    "    print(\"Mejores parámetros de DNN 3:\", best_params_dnn_3)\n",
    "    return best_params_dnn_1, best_params_dnn_2, best_params_dnn_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15aae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(data: str):\n",
    "    data_1d_train = pd.read_csv(data)\n",
    "    data_1d_train = data_1d_train.dropna()\n",
    "    dataresult_long_1d_train = file_features(data_1d_train, ds_type=\"buy\")\n",
    "    dataresult_short_1d_train = file_features(data_1d_train, ds_type=\"sell\")\n",
    "    best_params_dnn1_long, best_params_dnn2_long, best_params_dnn3_long = optimize_params(dataresult_long_1d_train)\n",
    "    best_params_dnn1_short, best_params_dnn2_short, best_params_dnn3_short = optimize_params(dataresult_short_1d_train)\n",
    "    \n",
    "    return best_params_dnn1_long, best_params_dnn2_long, best_params_dnn3_long, best_params_dnn1_short, best_params_dnn2_short, best_params_dnn3_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ec3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1_params_1d_long, dnn2_params_1d_long, dnn3_params_1d_long, dnn1_params_1d_short, dnn2_params_1d_short, dnn3_params_1d_short = params(\"aapl_1d_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8eabdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:35,132] A new study created in memory with name: no-name-2276d61a-5d46-4a16-9490-aa38d6796fb1\n",
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\957257836.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 2s 49ms/step - loss: 0.8746 - accuracy: 0.4461 - val_loss: 0.6959 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7056 - accuracy: 0.5196 - val_loss: 0.6902 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7001 - accuracy: 0.4853 - val_loss: 0.6923 - val_accuracy: 0.5385\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7035 - accuracy: 0.4951 - val_loss: 0.7066 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.4853 - val_loss: 0.6968 - val_accuracy: 0.4615\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:37,361] Trial 0 finished with value: 0.765625 and parameters: {'num_layers': 4, 'num_units_layer_0': 155, 'num_units_layer_1': 86, 'num_units_layer_2': 91, 'num_units_layer_3': 154, 'activation_layer_0': 'sigmoid', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'tanh', 'learning_rate': 0.005511010424661961}. Best is trial 0 with value: 0.765625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\957257836.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 62ms/step - loss: 0.7578 - accuracy: 0.4951 - val_loss: 0.7005 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7101 - accuracy: 0.4951 - val_loss: 0.6939 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5392 - val_loss: 0.6959 - val_accuracy: 0.4423\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5637 - val_loss: 0.6985 - val_accuracy: 0.5192\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5294 - val_loss: 0.6991 - val_accuracy: 0.4808\n",
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:38,840] Trial 1 finished with value: 0.421875 and parameters: {'num_layers': 1, 'num_units_layer_0': 100, 'activation_layer_0': 'tanh', 'learning_rate': 0.0001788644971700735}. Best is trial 0 with value: 0.765625.\n",
      "[I 2024-04-09 21:44:38,840] A new study created in memory with name: no-name-015ab260-b421-4b9a-8071-466124292928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 1: {'num_layers': 4, 'num_units_layer_0': 155, 'num_units_layer_1': 86, 'num_units_layer_2': 91, 'num_units_layer_3': 154, 'activation_layer_0': 'sigmoid', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'tanh', 'learning_rate': 0.005511010424661961}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\2212722417.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 34ms/step - loss: 2.9083 - accuracy: 0.4951 - val_loss: 2.2355 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4956 - accuracy: 0.5343 - val_loss: 0.8950 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0622 - accuracy: 0.4951 - val_loss: 0.7298 - val_accuracy: 0.4231\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8273 - accuracy: 0.5098 - val_loss: 0.7419 - val_accuracy: 0.4808\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.5833 - val_loss: 0.7081 - val_accuracy: 0.5385\n",
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:40,347] Trial 0 finished with value: 0.296875 and parameters: {'num_layers': 2, 'num_units_layer_0': 243, 'num_units_layer_1': 98, 'activation_layer_0': 'selu', 'activation_layer_1': 'selu', 'learning_rate': 0.00010975358159141193}. Best is trial 0 with value: 0.296875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\2212722417.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 34ms/step - loss: 32.9709 - accuracy: 0.4461 - val_loss: 6.8053 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0845 - accuracy: 0.5882 - val_loss: 4.2653 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7307 - accuracy: 0.5000 - val_loss: 1.5338 - val_accuracy: 0.4615\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8698 - accuracy: 0.5098 - val_loss: 0.7422 - val_accuracy: 0.4808\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7204 - accuracy: 0.4657 - val_loss: 0.7624 - val_accuracy: 0.4615\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:41,854] Trial 1 finished with value: 0.765625 and parameters: {'num_layers': 2, 'num_units_layer_0': 98, 'num_units_layer_1': 65, 'activation_layer_0': 'selu', 'activation_layer_1': 'relu', 'learning_rate': 0.01920628843877236}. Best is trial 1 with value: 0.765625.\n",
      "[I 2024-04-09 21:44:41,857] A new study created in memory with name: no-name-08dbaef1-12e1-4344-bf30-b3775be52f24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 2: {'num_layers': 2, 'num_units_layer_0': 98, 'num_units_layer_1': 65, 'activation_layer_0': 'selu', 'activation_layer_1': 'relu', 'learning_rate': 0.01920628843877236}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\3711254653.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 70ms/step - loss: 13.3154 - accuracy: 0.5343 - val_loss: 4.2150 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.4148 - accuracy: 0.4951 - val_loss: 2.8265 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.0399 - accuracy: 0.5343 - val_loss: 2.7582 - val_accuracy: 0.5385\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.0543 - accuracy: 0.5049 - val_loss: 2.2843 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6112 - accuracy: 0.5147 - val_loss: 1.5075 - val_accuracy: 0.5385\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B24A108720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:43,507] Trial 0 finished with value: 0.234375 and parameters: {'num_layers': 3, 'num_units_layer_0': 424, 'num_units_layer_1': 186, 'num_units_layer_2': 423, 'activation_layer_0': 'relu', 'activation_layer_1': 'selu', 'activation_layer_2': 'elu', 'learning_rate': 0.0014259664976853138}. Best is trial 0 with value: 0.234375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\3711254653.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 79ms/step - loss: 17.2216 - accuracy: 0.5245 - val_loss: 2.6269 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9208 - accuracy: 0.4951 - val_loss: 0.9356 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.0708 - accuracy: 0.5147 - val_loss: 1.4018 - val_accuracy: 0.5385\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2622 - accuracy: 0.5049 - val_loss: 1.5903 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9648 - accuracy: 0.5539 - val_loss: 1.1465 - val_accuracy: 0.5385\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B24B4C2DE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:45,966] Trial 1 finished with value: 0.234375 and parameters: {'num_layers': 5, 'num_units_layer_0': 314, 'num_units_layer_1': 96, 'num_units_layer_2': 132, 'num_units_layer_3': 434, 'num_units_layer_4': 196, 'activation_layer_0': 'relu', 'activation_layer_1': 'selu', 'activation_layer_2': 'selu', 'activation_layer_3': 'selu', 'activation_layer_4': 'selu', 'learning_rate': 0.0020037637981947594}. Best is trial 0 with value: 0.234375.\n",
      "[I 2024-04-09 21:44:45,967] A new study created in memory with name: no-name-4a3fdcbc-9fda-4380-9961-f35fe12ba714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 3: {'num_layers': 3, 'num_units_layer_0': 424, 'num_units_layer_1': 186, 'num_units_layer_2': 423, 'activation_layer_0': 'relu', 'activation_layer_1': 'selu', 'activation_layer_2': 'elu', 'learning_rate': 0.0014259664976853138}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\957257836.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 42ms/step - loss: 1.1763 - accuracy: 0.5049 - val_loss: 0.6908 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - accuracy: 0.5441 - val_loss: 0.7138 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6983 - accuracy: 0.5147 - val_loss: 0.6908 - val_accuracy: 0.5385\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6993 - accuracy: 0.4951 - val_loss: 0.6931 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.4363 - val_loss: 0.7030 - val_accuracy: 0.4615\n",
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:48,202] Trial 0 finished with value: 0.21875 and parameters: {'num_layers': 5, 'num_units_layer_0': 162, 'num_units_layer_1': 100, 'num_units_layer_2': 198, 'num_units_layer_3': 240, 'num_units_layer_4': 51, 'activation_layer_0': 'tanh', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'tanh', 'activation_layer_4': 'tanh', 'learning_rate': 0.00449320591078656}. Best is trial 0 with value: 0.21875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\957257836.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 36ms/step - loss: 0.7083 - accuracy: 0.4951 - val_loss: 0.6902 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.4853 - val_loss: 0.6957 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.5049 - val_loss: 0.7018 - val_accuracy: 0.4615\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6903 - accuracy: 0.5049 - val_loss: 0.7001 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5833 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:49,987] Trial 1 finished with value: 0.21875 and parameters: {'num_layers': 3, 'num_units_layer_0': 164, 'num_units_layer_1': 98, 'num_units_layer_2': 131, 'activation_layer_0': 'sigmoid', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'learning_rate': 0.00016452315735045173}. Best is trial 0 with value: 0.21875.\n",
      "[I 2024-04-09 21:44:49,987] A new study created in memory with name: no-name-5d0c93cb-658f-454e-bbdf-e4bf7771878e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 1: {'num_layers': 5, 'num_units_layer_0': 162, 'num_units_layer_1': 100, 'num_units_layer_2': 198, 'num_units_layer_3': 240, 'num_units_layer_4': 51, 'activation_layer_0': 'tanh', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'tanh', 'activation_layer_4': 'tanh', 'learning_rate': 0.00449320591078656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\2212722417.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 41ms/step - loss: 0.7034 - accuracy: 0.4461 - val_loss: 0.6993 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5098 - val_loss: 0.6951 - val_accuracy: 0.4423\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.5686 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6865 - accuracy: 0.5686 - val_loss: 0.6984 - val_accuracy: 0.4808\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.5539 - val_loss: 0.7003 - val_accuracy: 0.4808\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:52,111] Trial 0 finished with value: 0.421875 and parameters: {'num_layers': 4, 'num_units_layer_0': 249, 'num_units_layer_1': 131, 'num_units_layer_2': 68, 'num_units_layer_3': 101, 'activation_layer_0': 'relu', 'activation_layer_1': 'sigmoid', 'activation_layer_2': 'relu', 'activation_layer_3': 'relu', 'learning_rate': 0.0002490905120224322}. Best is trial 0 with value: 0.421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\2212722417.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 43ms/step - loss: 1.0088 - accuracy: 0.5343 - val_loss: 0.7262 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7281 - accuracy: 0.5833 - val_loss: 0.9210 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8567 - accuracy: 0.4755 - val_loss: 0.8512 - val_accuracy: 0.4615\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7524 - accuracy: 0.4657 - val_loss: 0.6913 - val_accuracy: 0.5385\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7383 - accuracy: 0.4951 - val_loss: 0.6906 - val_accuracy: 0.5385\n",
      "2/2 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:54,717] Trial 1 finished with value: 0.21875 and parameters: {'num_layers': 6, 'num_units_layer_0': 68, 'num_units_layer_1': 249, 'num_units_layer_2': 111, 'num_units_layer_3': 211, 'num_units_layer_4': 242, 'num_units_layer_5': 202, 'activation_layer_0': 'selu', 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'sigmoid', 'activation_layer_4': 'selu', 'activation_layer_5': 'selu', 'learning_rate': 0.0008014733276600091}. Best is trial 0 with value: 0.421875.\n",
      "[I 2024-04-09 21:44:54,734] A new study created in memory with name: no-name-219981f7-95e6-498b-839a-6f822f0fc3b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 2: {'num_layers': 4, 'num_units_layer_0': 249, 'num_units_layer_1': 131, 'num_units_layer_2': 68, 'num_units_layer_3': 101, 'activation_layer_0': 'relu', 'activation_layer_1': 'sigmoid', 'activation_layer_2': 'relu', 'activation_layer_3': 'relu', 'learning_rate': 0.0002490905120224322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\3711254653.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 3s 108ms/step - loss: 0.9975 - accuracy: 0.5000 - val_loss: 0.7024 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7769 - accuracy: 0.4657 - val_loss: 0.7835 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7922 - accuracy: 0.4608 - val_loss: 0.6971 - val_accuracy: 0.5192\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7261 - accuracy: 0.4755 - val_loss: 0.7118 - val_accuracy: 0.5385\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7366 - accuracy: 0.5294 - val_loss: 0.6913 - val_accuracy: 0.5385\n",
      "2/2 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:44:59,023] Trial 0 finished with value: 0.265625 and parameters: {'num_layers': 4, 'num_units_layer_0': 166, 'num_units_layer_1': 332, 'num_units_layer_2': 507, 'num_units_layer_3': 87, 'activation_layer_0': 'elu', 'activation_layer_1': 'relu', 'activation_layer_2': 'selu', 'activation_layer_3': 'relu', 'learning_rate': 1.0141650181481786e-05}. Best is trial 0 with value: 0.265625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp\\ipykernel_12388\\3711254653.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 86ms/step - loss: 8.5364 - accuracy: 0.5049 - val_loss: 9.0705 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 7.6188 - accuracy: 0.5049 - val_loss: 8.0196 - val_accuracy: 0.4615\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.6726 - accuracy: 0.5049 - val_loss: 6.9793 - val_accuracy: 0.4615\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.7624 - accuracy: 0.5049 - val_loss: 5.9470 - val_accuracy: 0.4615\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.8761 - accuracy: 0.5049 - val_loss: 4.9864 - val_accuracy: 0.4615\n",
      "2/2 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:45:01,377] Trial 1 finished with value: 0.78125 and parameters: {'num_layers': 5, 'num_units_layer_0': 120, 'num_units_layer_1': 194, 'num_units_layer_2': 254, 'num_units_layer_3': 196, 'num_units_layer_4': 111, 'activation_layer_0': 'relu', 'activation_layer_1': 'elu', 'activation_layer_2': 'relu', 'activation_layer_3': 'elu', 'activation_layer_4': 'relu', 'learning_rate': 1.4451941039038466e-05}. Best is trial 1 with value: 0.78125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros de DNN 3: {'num_layers': 5, 'num_units_layer_0': 120, 'num_units_layer_1': 194, 'num_units_layer_2': 254, 'num_units_layer_3': 196, 'num_units_layer_4': 111, 'activation_layer_0': 'relu', 'activation_layer_1': 'elu', 'activation_layer_2': 'relu', 'activation_layer_3': 'elu', 'activation_layer_4': 'relu', 'learning_rate': 1.4451941039038466e-05}\n"
     ]
    }
   ],
   "source": [
    "dnn1_params_1h_long, dnn2_params_1h_long, dnn3_params_1h_long, dnn1_params_1h_short, dnn2_params_1h_short, dnn3_params_1h_short = params(\"aapl_1h_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27acbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1_params_1m_long, dnn2_params_1m_long, dnn3_params_1m_long, dnn1_params_1m_short, dnn2_params_1m_short, dnn3_params_1m_short = params(\"aapl_1m_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23db886",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1_params_5m_long, dnn2_params_5m_long, dnn3_params_5m_long, dnn1_params_5m_short, dnn2_params_5m_short, dnn3_params_5m_short = params(\"aapl_5m_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40d14b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez actualizados los parametros optimos ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48ec07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_compile_dnn_model(input_shape, params):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(input_shape,)))\n",
    "    for i in range(params['num_layers']):\n",
    "        units = params[f'num_units_layer_{i}']\n",
    "        activation = params[f'activation_layer_{i}']\n",
    "        model.add(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26844608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_signals(data, best_dnn1_params, best_dnn2_params, best_dnn3_params):\n",
    "    buy_signals = pd.DataFrame()\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    input_shape = X.shape[1]\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Crear y compilar modelo DNN1\n",
    "    best_dnn1_model = create_and_compile_dnn_model(input_shape, best_dnn1_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn1_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn1 = best_dnn1_model.predict(X)\n",
    "    y_pred_rounded_dnn1 = (y_pred_dnn1 > threshold).astype('int32')\n",
    "    \n",
    "    # Crear y compilar modelo DNN2\n",
    "    best_dnn2_model = create_and_compile_dnn_model(input_shape, best_dnn2_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn2_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn2 = best_dnn2_model.predict(X)\n",
    "    y_pred_rounded_dnn2 = (y_pred_dnn2 > threshold).astype('int32')\n",
    "    \n",
    "    # Crear y compilar modelo DNN3\n",
    "    best_dnn3_model = create_and_compile_dnn_model(input_shape, best_dnn3_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn3_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn3 = best_dnn3_model.predict(X)\n",
    "    y_pred_rounded_dnn3 = (y_pred_dnn3 > threshold).astype('int32')\n",
    "\n",
    "    # Agregar las predicciones como nuevas columnas al conjunto de datos original\n",
    "    buy_signals['predicciones_dnn1'] = pd.Series(y_pred_rounded_dnn1.flatten())\n",
    "    buy_signals['predicciones_dnn2'] = pd.Series(y_pred_rounded_dnn2.flatten())\n",
    "    buy_signals['predicciones_dnn3'] = pd.Series(y_pred_rounded_dnn3.flatten())\n",
    "\n",
    "    return buy_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcab9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sell_signals(data, best_dnn1_params, best_dnn2_params, best_dnn3_params):\n",
    "    sell_signals = pd.DataFrame()\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    input_shape = X.shape[1]\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Crear y compilar modelo DNN1\n",
    "    best_dnn1_model = create_and_compile_dnn_model(input_shape, best_dnn1_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn1_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn1 = best_dnn1_model.predict(X)\n",
    "    y_pred_rounded_dnn1 = (y_pred_dnn1 > threshold).astype('int32')\n",
    "    \n",
    "    # Crear y compilar modelo DNN2\n",
    "    best_dnn2_model = create_and_compile_dnn_model(input_shape, best_dnn2_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn2_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn2 = best_dnn2_model.predict(X)\n",
    "    y_pred_rounded_dnn2 = (y_pred_dnn2 > threshold).astype('int32')\n",
    "    \n",
    "    # Crear y compilar modelo DNN3\n",
    "    best_dnn3_model = create_and_compile_dnn_model(input_shape, best_dnn3_params)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    best_dnn3_model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    y_pred_dnn3 = best_dnn3_model.predict(X)\n",
    "    y_pred_rounded_dnn3 = (y_pred_dnn3 > threshold).astype('int32')\n",
    "\n",
    "    # Agregar las predicciones como nuevas columnas al conjunto de datos original\n",
    "    sell_signals['predicciones_dnn1'] = pd.Series(y_pred_rounded_dnn1.flatten())\n",
    "    sell_signals['predicciones_dnn2'] = pd.Series(y_pred_rounded_dnn2.flatten())\n",
    "    sell_signals['predicciones_dnn3'] = pd.Series(y_pred_rounded_dnn3.flatten())\n",
    "\n",
    "    return sell_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4513c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, buy_signals, sell_signals, stop_loss, take_profit, n_shares):\n",
    "            history = []\n",
    "            active_operations = []\n",
    "            cash = 1_000_000\n",
    "            com = 1.25 / 100\n",
    "\n",
    "            for i, row in data.iterrows():\n",
    "                # close active operation\n",
    "                active_op_temp = []\n",
    "                for operation in active_operations:\n",
    "                    if operation[\"stop_loss\"] > row.Close:\n",
    "                        cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                    elif operation[\"take_profit\"] < row.Close:\n",
    "                        cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                    else:\n",
    "                        active_op_temp.append(operation)\n",
    "                active_operations = active_op_temp\n",
    "\n",
    "                # check if we have enough cash\n",
    "                if cash < (row.Close * (1 + com)):\n",
    "                    asset_vals = sum([operation[\"n_shares\"] * row.Close for operation in active_operations])\n",
    "                    portfolio_value = cash + asset_vals\n",
    "                    continue\n",
    "\n",
    "                # Apply buy signals\n",
    "                if buy_signals.loc[i].any():\n",
    "                    active_operations.append({\n",
    "                        \"bought\": row.Close,\n",
    "                        \"n_shares\": n_shares,\n",
    "                        \"stop_loss\": row.Close * stop_loss,\n",
    "                        \"take_profit\": row.Close * take_profit\n",
    "                    })\n",
    "\n",
    "                    cash -= row.Close * (1 + com) * n_shares\n",
    "\n",
    "                # Apply sell signals\n",
    "                if sell_signals.loc[i].any():\n",
    "                    active_op_temp = []\n",
    "                    for operation in active_operations:\n",
    "                        if operation[\"take_profit\"] < row.Close or operation[\"stop_loss\"] > row.Close:\n",
    "                            cash += (row.Close * operation[\"n_shares\"]) * (1 - com)\n",
    "                        else:\n",
    "                            active_op_temp.append(operation)\n",
    "                    active_operations = active_op_temp\n",
    "\n",
    "                asset_vals = sum([operation[\"n_shares\"] * row.Close for operation in active_operations])\n",
    "                portfolio_value = cash + asset_vals\n",
    "\n",
    "            return portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceefdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial, strategy, data):\n",
    "    portfolio_value = 0\n",
    "\n",
    "    stop_loss = trial.suggest_float(\"stop_loss\", 0.80, 0.90)\n",
    "    take_profit = trial.suggest_float(\"take_profit\", 1.01, 1.10)\n",
    "    n_shares = trial.suggest_int(\"n_shares\", 20, 50)\n",
    "\n",
    "    strat_params = {}\n",
    "\n",
    "    buy_signals = pd.DataFrame()\n",
    "    sell_signals = pd.DataFrame()\n",
    "\n",
    "    if \"dnn1\" in strategy:\n",
    "        buy_signals[\"dnn1\"] = global_buy_signals[\"predicciones_dnn1\"]\n",
    "        sell_signals[\"dnn1\"] = global_sell_signals[\"predicciones_dnn1\"]\n",
    "        \n",
    "    if \"dnn2\" in strategy:\n",
    "        buy_signals[\"dnn2\"] = global_buy_signals[\"predicciones_dnn2\"]\n",
    "        sell_signals[\"dnn2\"] = global_sell_signals[\"predicciones_dnn2\"]\n",
    "        \n",
    "    if \"dnn3\" in strategy:\n",
    "        buy_signals[\"dnn3\"] = global_buy_signals[\"predicciones_dnn3\"]\n",
    "        sell_signals[\"dnn3\"] = global_sell_signals[\"predicciones_dnn3\"]\n",
    "    \n",
    "    return backtest(data, buy_signals, sell_signals, stop_loss, take_profit, n_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af0abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_file(data):\n",
    "    data = data.drop(data.index[:30])\n",
    "    data = data.drop(data.index[-30:])\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    strategies = list(powerset([\"dnn1\", \"dnn2\", \"dnn3\"]))\n",
    "    best_strat = None\n",
    "    best_val = -1\n",
    "    best_params = None\n",
    "\n",
    "    for strat in strategies:\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda x: optimize(x, strat, data), n_trials=20)\n",
    "        value = study.best_value\n",
    "        if value > best_val:\n",
    "            best_val = value\n",
    "            best_strat = strat\n",
    "            best_params = study.best_params\n",
    "    print(study.best_value)\n",
    "    print(best_strat)\n",
    "    print(best_params)\n",
    "\n",
    "    return {\"file\": data,\n",
    "            \"strat\": best_strat,\n",
    "            \"value\": best_val,\n",
    "            \"params\": best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66607d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d_test = pd.read_csv(\"aapl_1d_test.csv\")\n",
    "data_1d_test = data_1d_test.dropna()\n",
    "dataresult_long_1d_test = file_features(data_1d_test, ds_type=\"buy\")\n",
    "dataresult_short_1d_test = file_features(data_1d_test, ds_type=\"sell\")\n",
    "global_buy_signals = buy_signals(dataresult_long_1d_test, dnn1_params_1d_long, dnn2_params_1d_long, dnn3_params_1d_long)\n",
    "global_sell_signals = sell_signals(dataresult_short_1d_test, dnn1_params_1d_short, dnn2_params_1d_short, dnn3_params_1d_short)\n",
    "file_1d_test = optimize_file(data_1d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f2831f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "130/130 [==============================] - 2s 4ms/step - loss: 0.7004 - accuracy: 0.5050 - val_loss: 0.6950 - val_accuracy: 0.4265\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 0.6940 - accuracy: 0.5103 - val_loss: 0.6886 - val_accuracy: 0.5735\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 0.6935 - accuracy: 0.5118 - val_loss: 0.6888 - val_accuracy: 0.5735\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5156 - val_loss: 0.6900 - val_accuracy: 0.5735\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5094 - val_loss: 0.6880 - val_accuracy: 0.5735\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 1s 3ms/step - loss: 4.3930 - accuracy: 0.4892 - val_loss: 0.8234 - val_accuracy: 0.4265\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.5130 - val_loss: 0.6875 - val_accuracy: 0.5514\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.5026 - val_loss: 0.7146 - val_accuracy: 0.4265\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.5060 - val_loss: 0.7278 - val_accuracy: 0.4265\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5183 - val_loss: 0.6979 - val_accuracy: 0.4265\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 2s 5ms/step - loss: 1.5677 - accuracy: 0.5132 - val_loss: 0.7118 - val_accuracy: 0.4265\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7254 - accuracy: 0.4983 - val_loss: 0.7145 - val_accuracy: 0.4265\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7093 - accuracy: 0.5036 - val_loss: 0.6913 - val_accuracy: 0.5735\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7046 - accuracy: 0.5149 - val_loss: 0.6859 - val_accuracy: 0.5735\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7176 - accuracy: 0.4916 - val_loss: 0.6818 - val_accuracy: 0.5735\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 2s 5ms/step - loss: 0.7176 - accuracy: 0.5017 - val_loss: 0.7177 - val_accuracy: 0.4256\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5099 - val_loss: 0.6837 - val_accuracy: 0.5744\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.5147 - val_loss: 0.6886 - val_accuracy: 0.5744\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.4974 - val_loss: 0.6823 - val_accuracy: 0.5744\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.5089 - val_loss: 0.6873 - val_accuracy: 0.5744\n",
      "163/163 [==============================] - 0s 1ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 2s 4ms/step - loss: 0.6940 - accuracy: 0.5168 - val_loss: 0.7027 - val_accuracy: 0.4256\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6909 - val_accuracy: 0.5744\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5156 - val_loss: 0.6833 - val_accuracy: 0.5744\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 0.6945 - accuracy: 0.5075 - val_loss: 0.6875 - val_accuracy: 0.5744\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5180 - val_loss: 0.6869 - val_accuracy: 0.5744\n",
      "163/163 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 2s 5ms/step - loss: 1.1491 - accuracy: 0.4825 - val_loss: 0.7094 - val_accuracy: 0.5744\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.5046 - val_loss: 0.6933 - val_accuracy: 0.5744\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.4942 - val_loss: 0.6923 - val_accuracy: 0.5668\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.5012 - val_loss: 0.6969 - val_accuracy: 0.5744\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.5089 - val_loss: 0.6921 - val_accuracy: 0.5648\n",
      "163/163 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-09 21:45:26,379] A new study created in memory with name: no-name-b4ae5b57-3585-4e47-bc03-22d6acd93812\n",
      "[I 2024-04-09 21:45:32,955] Trial 0 finished with value: 425447.2666882039 and parameters: {'stop_loss': 0.8537642483871418, 'take_profit': 1.019527590911823, 'n_shares': 48}. Best is trial 0 with value: 425447.2666882039.\n",
      "[I 2024-04-09 21:45:45,083] Trial 1 finished with value: 637778.4338516494 and parameters: {'stop_loss': 0.8853651582600753, 'take_profit': 1.048248129696119, 'n_shares': 27}. Best is trial 1 with value: 637778.4338516494.\n",
      "[I 2024-04-09 21:45:45,087] A new study created in memory with name: no-name-6a4b9fd5-a577-4357-bec3-8a1edd2285aa\n",
      "[I 2024-04-09 21:45:46,313] Trial 0 finished with value: 1000000.0 and parameters: {'stop_loss': 0.8932428009927589, 'take_profit': 1.088822405044012, 'n_shares': 39}. Best is trial 0 with value: 1000000.0.\n",
      "[I 2024-04-09 21:45:47,334] Trial 1 finished with value: 1000000.0 and parameters: {'stop_loss': 0.8022676154455103, 'take_profit': 1.0970580782078951, 'n_shares': 28}. Best is trial 0 with value: 1000000.0.\n",
      "[I 2024-04-09 21:45:47,334] A new study created in memory with name: no-name-6e1279fe-2210-4c44-9124-f5543cce3b74\n",
      "[I 2024-04-09 21:46:05,553] Trial 0 finished with value: 797332.7323364958 and parameters: {'stop_loss': 0.8986163502052744, 'take_profit': 1.0763320204965086, 'n_shares': 20}. Best is trial 0 with value: 797332.7323364958.\n",
      "[I 2024-04-09 21:46:15,427] Trial 1 finished with value: 588330.3068532231 and parameters: {'stop_loss': 0.8682169112937558, 'take_profit': 1.0423458812655202, 'n_shares': 42}. Best is trial 0 with value: 797332.7323364958.\n",
      "[I 2024-04-09 21:46:15,427] A new study created in memory with name: no-name-d95dda79-b91d-4275-ab31-ed65a0765537\n",
      "[I 2024-04-09 21:46:23,889] Trial 0 finished with value: 482811.4275838488 and parameters: {'stop_loss': 0.8636416907379942, 'take_profit': 1.0247118386124308, 'n_shares': 34}. Best is trial 0 with value: 482811.4275838488.\n",
      "[I 2024-04-09 21:46:40,362] Trial 1 finished with value: 761217.361068151 and parameters: {'stop_loss': 0.8996180181272398, 'take_profit': 1.0850792902902344, 'n_shares': 26}. Best is trial 1 with value: 761217.361068151.\n",
      "[I 2024-04-09 21:46:40,362] A new study created in memory with name: no-name-7127c6e0-c9ff-4cee-84fd-76714e1ca5db\n",
      "[I 2024-04-09 21:46:53,855] Trial 0 finished with value: 767628.3110303947 and parameters: {'stop_loss': 0.8454543060492411, 'take_profit': 1.0411200498274653, 'n_shares': 33}. Best is trial 0 with value: 767628.3110303947.\n",
      "[I 2024-04-09 21:47:10,074] Trial 1 finished with value: 934161.1863232538 and parameters: {'stop_loss': 0.8513323200588013, 'take_profit': 1.0685701128468237, 'n_shares': 31}. Best is trial 1 with value: 934161.1863232538.\n",
      "[I 2024-04-09 21:47:10,074] A new study created in memory with name: no-name-9a61f546-8205-4fcc-854e-e70b78d57468\n",
      "[I 2024-04-09 21:47:22,078] Trial 0 finished with value: 574291.7519610304 and parameters: {'stop_loss': 0.8900598902048715, 'take_profit': 1.0503137421774618, 'n_shares': 33}. Best is trial 0 with value: 574291.7519610304.\n",
      "[I 2024-04-09 21:47:33,577] Trial 1 finished with value: 668398.6607132433 and parameters: {'stop_loss': 0.8777085250402668, 'take_profit': 1.060499141673919, 'n_shares': 39}. Best is trial 1 with value: 668398.6607132433.\n",
      "[I 2024-04-09 21:47:33,577] A new study created in memory with name: no-name-e52c54db-a6fe-46e4-9fcd-4b684467a41c\n",
      "[I 2024-04-09 21:47:51,081] Trial 0 finished with value: 793956.8884173636 and parameters: {'stop_loss': 0.8934912727956545, 'take_profit': 1.0989880598840853, 'n_shares': 27}. Best is trial 0 with value: 793956.8884173636.\n",
      "[I 2024-04-09 21:48:03,326] Trial 1 finished with value: 838428.8239197981 and parameters: {'stop_loss': 0.8168462239818653, 'take_profit': 1.0408121406039614, 'n_shares': 41}. Best is trial 1 with value: 838428.8239197981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838428.8239197981\n",
      "('dnn2',)\n",
      "{'stop_loss': 0.8932428009927589, 'take_profit': 1.088822405044012, 'n_shares': 39}\n"
     ]
    }
   ],
   "source": [
    "data_1h_test = pd.read_csv(\"aapl_1h_test.csv\")\n",
    "data_1h_test = data_1h_test.dropna()\n",
    "dataresult_long_1h_test = file_features(data_1h_test, ds_type=\"buy\")\n",
    "dataresult_short_1h_test = file_features(data_1h_test, ds_type=\"sell\")\n",
    "global_buy_signals = buy_signals(dataresult_long_1h_test, dnn1_params_1h_long, dnn2_params_1h_long, dnn3_params_1h_long)\n",
    "global_sell_signals = sell_signals(dataresult_short_1h_test, dnn1_params_1h_short, dnn2_params_1h_short, dnn3_params_1h_short)\n",
    "file_1h_test = optimize_file(data_1h_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e434d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1m_test = pd.read_csv(\"aapl_1m_test.csv\")\n",
    "data_1m_test = data_1m_test.dropna()\n",
    "dataresult_long_1m_test = file_features(data_1m_test, ds_type=\"buy\")\n",
    "dataresult_short_1m_test = file_features(data_1m_test, ds_type=\"sell\")\n",
    "global_buy_signals = buy_signals(dataresult_long_1m_test, dnn1_params_1m_long, dnn2_params_1m_long, dnn3_params_1m_long)\n",
    "global_sell_signals = sell_signals(dataresult_short_1m_test, dnn1_params_1m_short, dnn2_params_1m_short, dnn3_params_1m_short)\n",
    "file_1m_test = optimize_file(data_1m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b191c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5m_test = pd.read_csv(\"aapl_5m_test.csv\")\n",
    "data_5m_test = data_5m_test.dropna()\n",
    "dataresult_long_5m_test = file_features(data_5m_test, ds_type=\"buy\")\n",
    "dataresult_short_5m_test = file_features(data_5m_test, ds_type=\"sell\")\n",
    "global_buy_signals = buy_signals(dataresult_long_5m_test, dnn1_params_5m_long, dnn2_params_5m_long, dnn3_params_5m_long)\n",
    "global_sell_signals = sell_signals(dataresult_short_5m_test, dnn1_params_5m_short, dnn2_params_5m_short, dnn3_params_5m_short)\n",
    "file_5m_test = optimize_file(data_5m_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
